{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from math import sqrt\n",
    "from numpy.random import seed\n",
    "from keras.regularizers import l1\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "seed = 6\n",
    "np.random.seed(seed)\n",
    "\n",
    "dataframe = pandas.read_csv(\"FullTest.csv\", header=0)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X_orig = dataset[:,0:8].astype(float)\n",
    "y_orig = dataset[:,8:12].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 1.]] [[0. 1. 0. 1.]]\n",
      "[[1. 1. 0. 0.]] [[0. 1. 0. 1.]]\n",
      "[[1. 1. 0. 0.]] [[1. 1. 0. 0.]]\n",
      "[[0. 1. 0. 1.]] [[0. 1. 0. 1.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 1. 0. 1.]] [[0. 1. 0. 1.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 1. 0. 1.]] [[1. 1. 0. 0.]]\n",
      "[[0. 1. 1. 0.]] [[0. 1. 1. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[1. 0. 0. 1.]] [[1. 0. 0. 1.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 1. 0. 0.]] [[0. 1. 0. 0.]]\n",
      "[[0. 1. 0. 0.]] [[0. 1. 0. 0.]]\n",
      "[[1. 0. 0. 0.]] [[1. 0. 0. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 1. 1. 0.]] [[0. 1. 0. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 1. 0. 0.]] [[0. 1. 0. 0.]]\n",
      "[[0. 1. 0. 0.]] [[0. 1. 0. 0.]]\n",
      "[[0. 1. 0. 1.]] [[0. 1. 0. 1.]]\n",
      "[[0. 1. 0. 1.]] [[0. 1. 0. 1.]]\n",
      "[[0. 0. 1. 0.]] [[0. 1. 1. 0.]]\n",
      "[[1. 1. 0. 0.]] [[1. 1. 0. 1.]]\n",
      "[[0. 1. 0. 1.]] [[0. 1. 0. 1.]]\n",
      "[[0. 1. 0. 0.]] [[0. 1. 0. 0.]]\n",
      "[[0. 0. 0. 1.]] [[0. 0. 0. 1.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[1. 0. 1. 0.]] [[1. 0. 1. 0.]]\n",
      "[[0. 0. 0. 1.]] [[0. 0. 0. 1.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "[[0. 1. 0. 0.]] [[0. 1. 0. 0.]]\n",
      "[[0. 0. 0. 1.]] [[0. 0. 0. 1.]]\n",
      "[[1. 1. 0. 0.]] [[1. 1. 0. 0.]]\n",
      "[[0. 1. 0. 0.]] [[0. 1. 0. 0.]]\n",
      "[[1. 1. 0. 0.]] [[1. 1. 0. 0.]]\n",
      "[[0. 1. 0. 1.]] [[0. 0. 0. 1.]]\n",
      "[[0. 0. 1. 0.]] [[0. 0. 1. 0.]]\n",
      "0.8775510204081632\n"
     ]
    }
   ],
   "source": [
    "# Function 2: The values of a single function is modified\n",
    "def generate_data2(training_data, number_samples):\n",
    "    random.seed(6)\n",
    "    generated_set = np.empty((0,12))\n",
    "    sampling_set1= [1,-1]\n",
    "    sampling_set2= [1,2,3] \n",
    "    \n",
    "    for i in range(number_samples):\n",
    "        row_index = i % len(training_data)\n",
    "        new_row = training_data[row_index,:].copy().reshape(1,12)\n",
    "        j = random.randint(0,3)\n",
    "        change_endors = np.random.choice(sampling_set1,1)\n",
    "        change_severity= np.random.choice(sampling_set2, 1)*change_endors\n",
    "        new_row[0,j] = new_row[0,j] + change_endors\n",
    "        if new_row[0, j] > 5:\n",
    "            new_row[0,j] = 5\n",
    "        \n",
    "        if new_row[0,j] <= 0:\n",
    "            new_row[0,j+4] = 0\n",
    "        else: \n",
    "            new_row[0,j+4] = new_row[0,j+4] + change_severity\n",
    "        \n",
    "        if new_row[0,j+4] > new_row[0,j]*3 :\n",
    "            new_row[0, j+4] = (new_row[0,j].copy())*3\n",
    "        \n",
    "        if new_row[0,j+4] < new_row[0,j] :\n",
    "            new_row[0, j+4] = (new_row[0,j].copy())\n",
    "            \n",
    "        \n",
    "        new_row[new_row < 0] = 0\n",
    "        \n",
    "        \n",
    "        generated_set = np.vstack((generated_set, new_row.flatten()))\n",
    "    \n",
    "    return generated_set\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='linear', input_dim=X_orig.shape[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(y_orig.shape[1], activation='sigmoid'))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for p in range(0, 49):\n",
    "\tX_copy = X_orig[(p):(p+1)]  #Slice the ith element from the numpy array\n",
    "\ty_copy = y_orig[(p):(p+1)]\n",
    "\tX_model = X_orig\n",
    "\ty_model = y_orig  #Set X and y equal to samples and labels\n",
    "\n",
    "\n",
    "\tX_model = np.delete(X_model, p, axis = 0)  #Create a new array to train the model with slicing out the ith item for LOOCV\n",
    "\ty_model = np.delete(y_model, p, axis = 0)\n",
    "\n",
    "\ttrain_set = np.concatenate((X_model, y_model), axis = 1) #combine numpy matrices \n",
    "\n",
    "\t\t\t\n",
    "\t#generated_data1 = generate_data1(train_set, 1000)  #run sample generator function\n",
    "\tgenerated_data2 = generate_data2(train_set, 1000)\n",
    "\t#generated_data3 = generate_data3(train_set, 1000)\n",
    "\t#generated_data4 = generate_data4(train_set, 1000)\n",
    "\n",
    "\tX_train = generated_data2[:,0:8].astype(float)\n",
    "\ty_train = generated_data2[:,8:12].astype(float)\n",
    "\n",
    "\tX_train2 = np.concatenate([X_train, X_model])\n",
    "\ty_train2 = np.concatenate([y_train, y_model])\n",
    "\n",
    "\n",
    "\n",
    "\tmodel.fit(X_train2, y_train2, epochs=40, batch_size=15, verbose=0)\n",
    "\tprediction = (model.predict(X_copy))\n",
    "\tprediction[prediction>=0.5] = 1\n",
    "\tprediction[prediction<0.5] = 0\n",
    "\tprint(prediction, y_copy)\n",
    "\tif np.array_equal(y_copy, prediction):\n",
    "\t\tj = j + 1\n",
    "\t\t#print(y_copy, prediction)\n",
    "\tif np.not_equal:\n",
    "\t\t#print(y_copy, prediction)\n",
    "\t\tpass\n",
    "print(j/49)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
